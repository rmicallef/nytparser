{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYT Article Data Parser\n",
    "\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# pull in the data from the Boydstun study\n",
    "data_path = '/home/ryan/work/nytparser/data/'\n",
    "data_file = 'Boydstun_random_3.csv'\n",
    "#data_file = 'Boydstun_NYT_FrontPage_Dataset TEST9Items.csv'\n",
    "data_location = data_path + data_file\n",
    "\n",
    "# topic codes used in the Boydstun study\n",
    "boydstun_topic_codes = {'1':'Macroeconomics',\n",
    "                        '2':'Civil Rights, Minority Issues, and Civil Liberties',\n",
    "                        '3':'Health',\n",
    "                        '4':'Agriculture',\n",
    "                        '5':'Labor, Employment, and Immigration',\n",
    "                        '6':'Education',\n",
    "                        '7':'Environment',\n",
    "                        '8':'Energy',\n",
    "                        \"9\":'Quality of Life',\n",
    "                        '10':'Transportation',\n",
    "                        '12':'Law, Crime, and Family Issues',\n",
    "                        '13':'Social Welfare',\n",
    "                        '14':'Community Development and Housing Issues',\n",
    "                        '15':'Banking, Finance, and Domestic Commerce',\n",
    "                        '16':'Defense',\n",
    "                        '17':'Space, Science, Technology and Communications',\n",
    "                        '18':'Foreign Trade',\n",
    "                        '19':'International Affairs and Foreign Aid',\n",
    "                        '20':'Government Operations',\n",
    "                        '21':'Public Lands and Water Management',\n",
    "                        '24':'State and Local Government Administration',\n",
    "                        '26':'Weather and Natural Disasters',\n",
    "                        '27':'Fires',\n",
    "                        '28':'Arts and Entertainment',\n",
    "                        '29':'Sports and Recreation',\n",
    "                        '30':'Death Notices',\n",
    "                        '31':'Churches and Religion',\n",
    "                        '99':'Other, Miscellaneous, and Human Interest',\n",
    "                       }\n",
    "\n",
    "boydstun_columns = defaultdict(list)\n",
    "\n",
    "with open(data_location, newline='') as csvfile:\n",
    "    rdr = csv.DictReader(csvfile)\n",
    "    for row in rdr:\n",
    "        for(k,v) in row.items():\n",
    "            boydstun_columns[k].append(v)\n",
    "\n",
    "boydstun_article_titles = boydstun_columns['title']\n",
    "boydstun_article_classes = boydstun_columns['topic_2digit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def URL_title(title):\n",
    "    \n",
    "    #title = \"\\\"\" + title + \"\\\"\"\n",
    "    return urllib.parse.quote(\"\\\"\" + title + \"\\\"\")\n",
    "       \n",
    "#URL_encoded_titles = []\n",
    "#\n",
    "#for title in boydstun_article_titles:\n",
    "#    title = \"\\\"\" + title + \"\\\"\"\n",
    "#    #print(title)\n",
    "#    URL_encoded_title = urllib.parse.quote(title)\n",
    "#    #print(URL_encoded_title)\n",
    "#    URL_encoded_titles.append(URL_encoded_title)\n",
    "\n",
    "#print(URL_encoded_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 article titles to search for.\n",
      "---> Fetching desriptions and class for article 0\n",
      "---> Fetching desriptions and class for article 1\n",
      "---> Fetching desriptions and class for article 2\n",
      "Articles pulled: 3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Get article data from NYT Developer API\n",
    "\n",
    "# Build the query\n",
    "\n",
    "# For reference\n",
    "#base_url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json?'\n",
    "#API_key = 'MEt3Ki6vTVUvG4unee31Sb6MuSq1ACVO'\n",
    "# Test URL\n",
    "#url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=MEt3Ki6vTVUvG4unee31Sb6MuSq1ACVO&begin_date=19960101&end_date=20061231&fq=headline:(%22Tax%20Panel%20Says%20Popular%20Breaks%20Should%20Be%20Cut%22)&fq=print_page:1'\n",
    "\n",
    "\n",
    "\n",
    "print(\"Found \" + str(len(boydstun_article_titles)) + \" article titles to search for.\")\n",
    "\n",
    "article_descriptions = []\n",
    "i = 0\n",
    "\n",
    "for title in boydstun_article_titles:\n",
    "    \n",
    "    # Build a list of article descriptions\n",
    "    print(\"---> Fetching desriptions and class for article \" + str(i))\n",
    "    #print(title)\n",
    "            \n",
    "    try:\n",
    "        \n",
    "        # Get an article\n",
    "        url = 'https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=MEt3Ki6vTVUvG4unee31Sb6MuSq1ACVO&begin_date=19960101&end_date=20061231&fq=headline:(' + URL_title(title) + ')&fq=print_page:1'\n",
    "        response = urllib.request.urlopen(url)\n",
    "        json_response = json.loads(response.read())\n",
    "        #print(json.dumps(json_dict, indent=4))\n",
    "            \n",
    "        # Extract available descriptions from each doc\n",
    "        for doc in json_response['response']['docs']:\n",
    "            \n",
    "            if 'snippet' in doc:\n",
    "                #print(doc['snippet'])\n",
    "                snippet = doc['snippet']\n",
    "            else:\n",
    "                snippet = ''\n",
    "\n",
    "            if 'lead_paragraph' in doc:\n",
    "                #print(doc['lead_paragraph'])\n",
    "                lead_paragraph = doc['lead_paragraph']\n",
    "            else:\n",
    "                lead_paragraph = ''\n",
    "\n",
    "            article_descriptions.append(title + snippet + lead_paragraph)\n",
    "\n",
    "            \n",
    "            if i%10 == 0:\n",
    "                # preserve state\n",
    "                pickle_file = open(data_location + '.pkl', 'wb')\n",
    "                pickle.dump(article_descriptions, pickle_file)\n",
    "                pickle_file.close()\n",
    "                \n",
    "            i+=1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(type(e))\n",
    "    \n",
    "    time.sleep(6) #limit enforced by NYT\n",
    "\n",
    "print(\"Articles pulled: \" + str(len(article_descriptions)))\n",
    "#print(article_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 articles.\n",
      "---> Working on article 0: topic: Transportation\n",
      "---> Working on article 1: topic: International Affairs and Foreign Aid\n",
      "---> Working on article 2: topic: Education\n"
     ]
    }
   ],
   "source": [
    "# Transform to useful format\n",
    "\n",
    "\"\"\"\n",
    "Goal output:\n",
    "\n",
    "{\"text\": \"some text\", \"label\": \"politics\"}\n",
    "{\"text\": \"some other text\", \"label\": \"science\"}\n",
    "\"\"\"\n",
    "\n",
    "output_list = []\n",
    "\n",
    "print('Found ' + str(len(article_descriptions)) + ' articles.')\n",
    "\n",
    "\n",
    "for i in range(len(article_descriptions)):\n",
    "    \n",
    "    print('---> Working on article ' + str(i) + ': topic: ' + str(boydstun_topic_codes[boydstun_article_classes[i]]))\n",
    "    \n",
    "    article_dict = {}\n",
    "    \n",
    "    try:\n",
    "        article_dict['text'] = article_descriptions[i]\n",
    "        article_dict['label'] = str(boydstun_topic_codes[boydstun_article_classes[i]])\n",
    "        output_list.append(article_dict)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(type(e))\n",
    "        \n",
    "with open(data_location + '.json', 'w') as outfile:\n",
    "    json.dump(output_list, outfile, separators=(',', ':'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
